<!DOCTYPE html><html lang="en-US"><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><script>!function(){try {var d=document.documentElement.classList;d.remove('light','dark');var e=localStorage.getItem('theme');if(!e)return localStorage.setItem('theme','system'),d.add('system');if("system"===e){var t="(prefers-color-scheme: dark)",m=window.matchMedia(t);m.media!==t||m.matches?d.add('dark'):d.add('light')}else d.add(e)}catch(e){}}()</script><title>Paradoxes and Cognitive Biases</title><meta name="description" content="A brief review of some of my favorite paradoxes and cognitive biases."/><meta property="og:type" content="website"/><meta name="og:title" property="og:title" content="Paradoxes and Cognitive Biases"/><meta name="og:description" property="og:description" content="A brief review of some of my favorite paradoxes and cognitive biases."/><meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Paradoxes and Cognitive Biases"/><meta name="twitter:description" content="A brief review of some of my favorite paradoxes and cognitive biases."/><meta name="twitter:creator" content="franciscojarceo"/><link rel="icon" type="image/png" href="/favicon.ico"/><link rel="apple-touch-icon" href="/favicon.ico"/><meta name="next-head-count" content="14"/><link rel="preload" href="/_next/static/css/4c5a21ffd3cac99f4659.css" as="style"/><link rel="stylesheet" href="/_next/static/css/4c5a21ffd3cac99f4659.css" data-n-g=""/><noscript data-n-css=""></noscript><link rel="preload" href="/_next/static/chunks/main-39418da170c6bb422e22.js" as="script"/><link rel="preload" href="/_next/static/chunks/webpack-e067438c4cf4ef2ef178.js" as="script"/><link rel="preload" href="/_next/static/chunks/framework.9707fddd9ae5927c17c3.js" as="script"/><link rel="preload" href="/_next/static/chunks/commons.a6f6c255f30e2cc8ab2c.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/_app-6bd4657ff7c26af8364b.js" as="script"/><link rel="preload" href="/_next/static/chunks/5e7de4f36e438e169c5d145e7df90137ae956f1e.c55db21543619f2e3353.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/post/%5Bslug%5D-f7cba0a36d81c7b5f6f1.js" as="script"/></head><body><div id="__next"><div class="w-full min-h-screen dark:bg-gray-700 dark:text-white"><div class="max-w-screen-md px-4 py-12 mx-auto antialiased font-body"><header class="flex items-center justify-between  mb-2"><meta name="description" content="My chaotic thoughts on computers, statistics, finance, and data"/><meta name="keywords" content="francisco javier arceo, data science, finance, fintech, engineering, django, python"/><meta property="og:type" content="website"/><meta property="og:title" content="Francisco&#x27;s Random Thoughts"/><meta property="og:locale" content="en_US"/><meta property="og:description" content="My chaotic thoughts on computers, statistics, finance, and data"/><meta property="og:image" content="https://og-image.now.sh/Francisco&#x27;s%20Random%20Thoughts.png?theme=light&amp;md=0&amp;fontSize=75px&amp;images=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Ffront%2Fassets%2Fdesign%2Fnextjs-black-logo.svg"/><meta name="twitter:description" content="My chaotic thoughts on computers, statistics, finance, and data"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:site" content="franciscojarceo"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-71125809-1/"></script><script src="/ga.js"></script><div class="max-w-md"><a><a class="text-2xl font-black text-black no-underline font-display dark:text-white" href="/">Francisco Javier Arceo</a></a></div><script></script></header><main style="padding-bottom:10px"><article><header class="mb-8"><h1 class="mb-2 text-6xl font-black leading-none font-display">Paradoxes and Cognitive Biases</h1><p class="text-sm">May 26, 2022</p></header><div class="mb-4 prose lg:prose-lg dark:prose-dark"><h1>The Irrationality of Humans</h1><p>I find human behavior and decision making wildly fascinating...and mostly comical,
especially my own. This is because of the variety of paradoxes, cognitive biases,
and irrationalities that are constantly at play in our micro and macro conclusions.</p><p>In fact, these irrational behaviors are largely what led me into the career I have today.
It all started with <em>economics and statistics</em> (my first graduate degree/love)
and I&#x27;ve spent ten years working in understanding human behavior. Maybe the methods
and engineering are fancier now than back then but, at my core, I am still
fascinated by human behavior, data, and statistical inference—the methods that
provide a glimpse of understanding about a person&#x27;s choices.</p><p>What I&#x27;ve found is that humans are just kind of <em><strong>weird</strong></em> in their
behaviors and decision making. Some would say down right irrational...I certainly
would.</p><p>Much of that irrationality comes from all sorts of paradoxes and cognitive
biases that are well known in different academic disciplines (particularly
behavioral economics and statistics) but that aren&#x27;t as well known by most
folks. So I thought I&#x27;d write briefly about them and why they&#x27;re important.</p><p>It&#x27;s worth emphasizing that even if you are aware of these things, you are still quite
likely to be subject to them or make the mistakes they call out—<em><strong>I do all of the
time</strong></em>. Regardless, knowing them can—to some degree—help you mitigate them
and help you make better decisions.</p><p>I would like to over-emphasize that my own decision making is nothing to brag
about but I decided to write this because I thought it&#x27;d be fun and I do love
this topic.</p><h1>Paradoxes and Biases</h1><p>I have decided to explicitly order these in the order I felt is the most
important. This, too, is ridden with bias but I believe that this is the
order most important to me and that I&#x27;ve found the most useful in my
personal and professional life.</p><h2>00. The Dunning-Kruger Effect</h2><p><a href="https://en.wikipedia.org/wiki/Dunning%E2%80%93Kruger_effect">The Dunning-Kruger Effect</a>
is one of the most important cognitive biases that exist, probably because of how
impactful it is to everyone (i.e., we all suffer from the burden of incompetent
people and it is quite likely we, too, are someone&#x27;s burden).</p><p>In short, people with low ability at a given task tend to overestimate their
ability and those with high ability tend to underestimate it.</p><p>If you pay attention, you will see this occurrence often...especially from
those without much experience in a given area of expertise (though this is not
always true).</p><p>You may see this often from people in business...run away.</p><h2>01. The Double Standard</h2><p>This is probably my favorite bias because people (like me, for example) commit
this often and it&#x27;s such a subtle yet common thing. I believe this bias to be a
consequence of the Dunning-Kruger Efect mentioned above.</p><p>Definitionally, a Double Standard is &quot;the application of different sets of
principles for situations that are, in principle, the same.&quot;</p><p>I find this to be very important professionally as people often have unrealistic
expectations of others that they wouldn&#x27;t have of themselves. I find this
comes up when folks without domain expertise are frustrated by timelines of
for building various things.</p><p>Said another way, <em>&quot;Why does this take so long?&quot;</em></p><p>As a manager, I regularly ask myself &quot;If I were doing this, would I expect the
same outcome in the same time?&quot; and I find that this helps me better empathize
and be more realistic about the outcomes.</p><p>More importantly, my colleagues probably find me more tolerable. :)</p><h2>02. The Curse of Knowledge</h2><p>I say this non-ironically: something is obvious when you know it, and not
if you don&#x27;t—so too the definition of <a href="https://en.wikipedia.org/wiki/Curse_of_knowledge">the Curse of Knowledge</a>.</p><p>This is something I experienced a lot in my career because people often forget
all of the context they have when referencing something. Business is very
jargony so when I onboard people or explain things I very explicitly try to
avoid using acronyms or cryptic language. It certainly takes mental effort but
it makes it much less frustrating for the other party.</p><p>Also, I find that assuming someone knows something or being surprised that
someone <em>doesn&#x27;t</em> know something can sound extremely condescending, so probably
it may be best to avoid that.</p><h2>03. Simpson&#x27;s Paradox</h2><p>I could write an entire post about <a href="https://en.wikipedia.org/wiki/Simpson%27s_paradox">Simpson&#x27;s Paradox</a>
but, to keep it brief, Simpson&#x27;s Paradox is a statistical phenomenon in which a
correlation between two variables can be reversed by the addition of another.</p><p>But how??? Time for a graph!</p><p><picture class="w-full"><source type="image/webp" data-srcset="/_next/static/images/simpsons_paradox_1-22601e998b25651a904ad94d57c331ce.png.webp"/><source type="image/png" data-srcset="/_next/static/images/simpsons_paradox_1-fc279018afc58f7a144c37433aeecdcd.png"/><img class="lazyload blur w-full" alt="Simpson&#x27;s Paradox: Negative Correlation" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAHCAYAAAAxrNxjAAAAAklEQVR4AewaftIAAAC4SURBVF3BMWrDQBBA0T/DaldCKCqSTi7SBAy+/w18gRQqlcJgXJhsChlJ28wEFYHg96SU4uu6klIixoiI8ExE0BgjL6p8326M40gphWVZeKbuzhYC27Kw3e98ns/knJmmCTNjZ2YEdyfGyPvxyNvhQM6Zn8sFN+NrXXkdBrquI6gq7s6u73uqqqJtW+Z55n69Uh4PPk4ngrvzX9M01HVN3/cMw0CMEVUliAjujojwx8xIKWFmqCq7Xx2NUjscQH2kAAAAAElFTkSuQmCC"/></picture></p><p>Above variables <!-- --> and <!-- --> are negatively correlated, quite strongly too with
a correlation coefficient of -0.74. But what if there was some other group
variable <!-- --> which represented 5 groups, we would then be able to see:</p><p><picture class="w-full"><source type="image/webp" data-srcset="/_next/static/images/simpsons_paradox_2-3a533efbe9d21193cb76a34ca3b950ed.png.webp"/><source type="image/png" data-srcset="/_next/static/images/simpsons_paradox_2-5842ae689697a38d508f511093af7e03.png"/><img class="lazyload blur w-full" alt="Simpson&#x27;s Paradox: Positive Correlation" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAHCAYAAAAxrNxjAAAAAklEQVR4AewaftIAAAC2SURBVE3B3UoDMRCA0W8mmWY3rhFWEW/EG9//qQqiKJX+bNvtJiO9EHqOzPPs0zRhZtRaUVFsZZgZt9TMKKWQ5kS3rvSuXAjQGlcigogQ3R3/3cO2sc7Kx8+Z12Hi0w+85RHNd3A6Et0deRjgvvJYhbT/ZnPeUsKRw+aLfvdMHF+Iqoq7IyFQotAxMPqJ2hbSDlQnKAvR3bllqwz5CS4LvPcQIogQRQR3R0T456lDc6C1hqpy9Qd6j0nGVC3AFwAAAABJRU5ErkJggg=="/></picture></p><p>Oh no! The exact opposite conclusion! It&#x27;s worth knowing that in statistics and
in life, you may never know of the existance of <!-- -->.</p><p>So while this is useful for regression and statistical inference, I find this
paradox to be applicable to many more situations.</p><p>Simply, I may <em>always</em> be missing a single, critical piece of information that
may flip my conclusion. So I tend to calibrate my opinions accordingly.</p><h2>04. The Sunk Cost Fallacy</h2><p>As elegantly written by <a href="https://thedecisionlab.com/biases/the-sunk-cost-fallacy">The Decision Lab</a>,
&quot;The Sunk Cost Fallacy describes our tendency to follow through on an endeavor
if we have already invested time, effort, or money into it, whether or not the
current costs outweigh the benefits.&quot;</p><p>Emotion often clutters our ability to understand the <em>actual</em> expected
value/reward of a given thing we are putting effort into but sometimes it is
in our best interest to cut our losses rather than see it through.</p><p>It rarely feels good but can often be the optimal decision.</p><h2>06. Loss Aversion</h2><p>Loss aversion is simply the disproportional weight a person often places on
minimizing losses to acquire economic gains.</p><p>For example, someone may prefer to take $10 with 100% certainty rather than
$20 with 90% certainty because the displeasure from that 10% possibility
outweighs the pleasure they&#x27;d receive from the additional $10 (or expected
$8 = (0.9 * 20) - 10).</p><p>This is extremely irrational and puts non-disciplined investors at a mathematical
disadvantage.</p><h2>07. The Gambler&#x27;s Fallacy</h2><p>The <a href="https://en.wikipedia.org/wiki/Gambler%27s_fallacy">Gambler&#x27;s Fallacy</a>
refers to the incorrect belief that a given event is more
or less likely given a previous sequence of events when the event is not a
function of time.</p><p>This can be seen through coin flips. If you see 5 heads flipped in a row, you
may think that a tails is &quot;due&quot; but this is incorrect (assuming a fair coin) since
coin flips are always independent (i.e., one flip doesn&#x27;t depend on the next).</p><h2>08. Anchoring</h2><p>Pulling again from <a href="https://thedecisionlab.com/biases/anchoring-bias">the Decision Lab</a>,
&quot;Anchoring is a cognitive bias that causes us to rely too heavily on the first
piece of information we are given about a topic. When we are setting plans or
making estimates about something, we interpret newer information from the
reference point of our anchor, instead of seeing it objectively.&quot;</p><p>This is often used in marketing and pricing to delude you into thinking
something is on sale. :&#x27;)</p><h2>09. Sample Bias</h2><p>Sample bias originates from statistics and is a result of a flawed collection
of an intended random sample.</p><p>This is particularly common in business and Twitter where people think their
customers or Twitter poll-responders are representative of the entire
population.</p><p>They&#x27;re not and this can often lead to very poor decision making or conclusions.</p><h2>10. Assignment Bias</h2><p><a href="https://www.statisticshowto.com/assignment-bias/#:~:text=Assignment%20bias%20happens%20when%20experimental,people%20who%20are%20significantly%20smarter.">Assignment Bias</a>
is similar to Sample Bias in that it is a bias in the sample
but is rooted in a broken assignment system. For example, imagine an
experimental drug trial where the &quot;random assignment machine&quot; (i.e., a machine
that assigns things at random) only treated the young and healthy,
while that is a pathological and extreme example it highlights the issue.</p><p>By the way, it turns out that a good &quot;random&quot; sample is extremely hard to
collect in the real world—ask the Census.</p><h2>11. Self-Selection Bias</h2><p><a href="https://en.wikipedia.org/wiki/Self-selection_bias">Self-Selection Bias</a>
is another form of sample bias but it&#x27;s caused by the participants choosing
whether or not to participate in the experiment or treatment.</p><p>Again, in the example above imagine instead that the &quot;random assignment
machine&quot; only treated the people who wanted to be treated and not the
ones that did.</p><p>Similar to the previous case it would ruin the experiment.</p><h2>12. Decision Fatigue</h2><p><a href="https://en.wikipedia.org/wiki/Decision_fatigue">Decision Fatigue</a> is a
phenomenon whereby an individual&#x27;s decision making quality deteriorates after a
long session of decision making.</p><p>In short, you get tired of making choices and you start to get sloppy. In the
business and investing world, this is extremely consequential because your or
your investor&#x27;s money is on the line.</p><h2>13. Optimism Bias</h2><p>To quote Wikipedia, &quot;<a href="https://en.wikipedia.org/wiki/Optimism_bias">Optimism Bias</a>
is a cognitive bias that causes someone to believe that they themselves are less
likely to experience a negative event. It is also known as unrealistic optimism
or comparative optimism.&quot;</p><p>It is good to be optimistic but it is <em>good-er</em> to balance it in reality.</p><h2>14. Response Bias</h2><p><a href="https://en.wikipedia.org/wiki/Response_bias">Response Bias</a> is both interesting
and counterintuitive.</p><p>It is catch-all for the frequent tendency of participants to respond
inaccurately or falsely to survey questions. This is part of the reason surveys
often conflict with reality.</p><p>As a statistician, I feel surverys are <em>kind of</em> useful but behaviors reveal the
truth. Measure behaviors.</p><p>For internet companies, you may find that user-survery metrics conflict with
tracking metrics that you have for your customer. What people say and what they
do are often wildly different.</p><h2>15. The Accuracy Paradox</h2><p>Lastly, <a href="https://en.wikipedia.org/wiki/Accuracy_paradox">The Accuracy Paradox</a>
is the paradoxical finding that Accuracy isn&#x27;t necessarily a good metric for for
measuring statistical or machine learning models.</p><p>This is because of an imbalance of outcomes.</p><p>Suppose I was trying to predict a whether someone had a rare illness (1
out of 10,000 people have it), if I predicted everyone didn&#x27;t have it I&#x27;d still
have 99.99% accuracy.</p><p>So, accuracy can often be quite useless as a metric for assessing the
quality of things in general (though not always).</p><h1>Managing the Irrational</h1><p>You <em>probably</em> can&#x27;t completely stop yourself from irrational decision making
but you can <em>possibly</em> manage it.</p><p>My approach is simple: acknowledge the biases above, the idiosyncratic ones I have
from my life exeriences, and reflect frequently. I find that this results in me
changing my mind often.</p><p>This can be frustrating but I think that early reactions or understandings
are often not the optimal ones so I try to put effort into reflecting so that I
can just do better.</p><h1>Some Advice</h1><p>(this advice may or may not be useful)</p><p>Being objective is nearly impossible when it relates to human judgement, and I&#x27;m
not even exactly sure what &quot;objective&quot; <em>really</em> means outside of mathematics.</p><p>But my advice on being as objective as possible is to write things down:
bullet points, a simple pros and cons list, or whatever suits you can highlight
flaws in your judgement and reasoning.</p><p>I find this brings me mental clarity more than anything else really. I also
tend to write things down on paper the good ol&#x27; fashion way (maybe it&#x27;s an
old habit grounded in problem sets, who knows).</p><p>Managing cognitive biases and mitigating the adverse consequences they may hold
is extremely challenging but a well worthy endeavor, as good decisions compound
like great investments.</p><p>But don&#x27;t worry too much if you find yourself struggling with it, we are all
human after all.</p><p>-Francisco</p></div></article></main><footer class="text-lg font-light"><div style="padding-top:10px;padding-bottom:10px"><a class="text-lg font-bold" href="/">← Back home</a></div><hr/><div><p>Like this blog? Check out the code on my<!-- --> <a href="https://github.com/franciscojavierarceo/franciscojavierarceo.github.io">GitHub</a>.</p><p>Built with<!-- --> <a href="https://nextjs.org/">Next.js</a> and ☕</p></div></footer></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"frontmatter":{"title":"Paradoxes and Cognitive Biases","description":"A brief review of some of my favorite paradoxes and cognitive biases.","date":"May 26, 2022"},"post":{"content":"\n# The Irrationality of Humans\n\nI find human behavior and decision making wildly fascinating...and mostly comical,\nespecially my own. This is because of the variety of paradoxes, cognitive biases,\nand irrationalities that are constantly at play in our micro and macro conclusions.\n\nIn fact, these irrational behaviors are largely what led me into the career I have today.\nIt all started with *economics and statistics* (my first graduate degree/love)\nand I've spent ten years working in understanding human behavior. Maybe the methods\nand engineering are fancier now than back then but, at my core, I am still\nfascinated by human behavior, data, and statistical inference—the methods that\nprovide a glimpse of understanding about a person's choices.\n\nWhat I've found is that humans are just kind of ***weird*** in their\nbehaviors and decision making. Some would say down right irrational...I certainly\nwould.\n\nMuch of that irrationality comes from all sorts of paradoxes and cognitive\nbiases that are well known in different academic disciplines (particularly\nbehavioral economics and statistics) but that aren't as well known by most\nfolks. So I thought I'd write briefly about them and why they're important.\n\nIt's worth emphasizing that even if you are aware of these things, you are still quite\nlikely to be subject to them or make the mistakes they call out—***I do all of the\ntime***. Regardless, knowing them can—to some degree—help you mitigate them\nand help you make better decisions.\n\nI would like to over-emphasize that my own decision making is nothing to brag\nabout but I decided to write this because I thought it'd be fun and I do love\nthis topic.\n\n# Paradoxes and Biases\n\nI have decided to explicitly order these in the order I felt is the most\nimportant. This, too, is ridden with bias but I believe that this is the\norder most important to me and that I've found the most useful in my\npersonal and professional life.\n\n## 00. The Dunning-Kruger Effect\n\n[The Dunning-Kruger Effect](https://en.wikipedia.org/wiki/Dunning%E2%80%93Kruger_effect)\nis one of the most important cognitive biases that exist, probably because of how\nimpactful it is to everyone (i.e., we all suffer from the burden of incompetent\npeople and it is quite likely we, too, are someone's burden).\n\nIn short, people with low ability at a given task tend to overestimate their\nability and those with high ability tend to underestimate it.\n\nIf you pay attention, you will see this occurrence often...especially from\nthose without much experience in a given area of expertise (though this is not\nalways true).\n\nYou may see this often from people in business...run away.\n\n## 01. The Double Standard\n\nThis is probably my favorite bias because people (like me, for example) commit\nthis often and it's such a subtle yet common thing. I believe this bias to be a\nconsequence of the Dunning-Kruger Efect mentioned above.\n\nDefinitionally, a Double Standard is \"the application of different sets of\nprinciples for situations that are, in principle, the same.\"\n\nI find this to be very important professionally as people often have unrealistic\nexpectations of others that they wouldn't have of themselves. I find this\ncomes up when folks without domain expertise are frustrated by timelines of\nfor building various things.\n\nSaid another way, *\"Why does this take so long?\"*\n\nAs a manager, I regularly ask myself \"If I were doing this, would I expect the\nsame outcome in the same time?\" and I find that this helps me better empathize\nand be more realistic about the outcomes.\n\nMore importantly, my colleagues probably find me more tolerable. :)\n\n## 02. The Curse of Knowledge\n\nI say this non-ironically: something is obvious when you know it, and not\nif you don't—so too the definition of [the Curse of Knowledge](https://en.wikipedia.org/wiki/Curse_of_knowledge).\n\nThis is something I experienced a lot in my career because people often forget\nall of the context they have when referencing something. Business is very\njargony so when I onboard people or explain things I very explicitly try to\navoid using acronyms or cryptic language. It certainly takes mental effort but\nit makes it much less frustrating for the other party.\n\nAlso, I find that assuming someone knows something or being surprised that\nsomeone *doesn't* know something can sound extremely condescending, so probably\nit may be best to avoid that.\n\n## 03. Simpson's Paradox\n\nI could write an entire post about [Simpson's Paradox](https://en.wikipedia.org/wiki/Simpson%27s_paradox)\nbut, to keep it brief, Simpson's Paradox is a statistical phenomenon in which a\ncorrelation between two variables can be reversed by the addition of another.\n\nBut how??? Time for a graph!\n\n![Simpson's Paradox: Negative Correlation](simpsons_paradox_1.png)\n\nAbove variables $X$ and $Y$ are negatively correlated, quite strongly too with\na correlation coefficient of -0.74. But what if there was some other group\nvariable $Z$ which represented 5 groups, we would then be able to see:\n\n![Simpson's Paradox: Positive Correlation](simpsons_paradox_2.png)\n\nOh no! The exact opposite conclusion! It's worth knowing that in statistics and\nin life, you may never know of the existance of $Z$.\n\nSo while this is useful for regression and statistical inference, I find this\nparadox to be applicable to many more situations.\n\nSimply, I may *always* be missing a single, critical piece of information that\nmay flip my conclusion. So I tend to calibrate my opinions accordingly.\n\n## 04. The Sunk Cost Fallacy\n\nAs elegantly written by [The Decision Lab](https://thedecisionlab.com/biases/the-sunk-cost-fallacy),\n\"The Sunk Cost Fallacy describes our tendency to follow through on an endeavor\nif we have already invested time, effort, or money into it, whether or not the\ncurrent costs outweigh the benefits.\"\n\nEmotion often clutters our ability to understand the *actual* expected\nvalue/reward of a given thing we are putting effort into but sometimes it is\nin our best interest to cut our losses rather than see it through.\n\nIt rarely feels good but can often be the optimal decision.\n\n## 06. Loss Aversion\n\nLoss aversion is simply the disproportional weight a person often places on\nminimizing losses to acquire economic gains.\n\nFor example, someone may prefer to take \\$10 with 100% certainty rather than\n\\$20 with 90% certainty because the displeasure from that 10\\% possibility\noutweighs the pleasure they'd receive from the additional \\$10 (or expected\n\\$8 = (0.9 * 20) - 10).\n\nThis is extremely irrational and puts non-disciplined investors at a mathematical\ndisadvantage.\n\n## 07. The Gambler's Fallacy\n\nThe [Gambler's Fallacy](https://en.wikipedia.org/wiki/Gambler%27s_fallacy)\nrefers to the incorrect belief that a given event is more\nor less likely given a previous sequence of events when the event is not a\nfunction of time.\n\nThis can be seen through coin flips. If you see 5 heads flipped in a row, you\nmay think that a tails is \"due\" but this is incorrect (assuming a fair coin) since\ncoin flips are always independent (i.e., one flip doesn't depend on the next).\n\n## 08. Anchoring\n\nPulling again from [the Decision Lab](https://thedecisionlab.com/biases/anchoring-bias),\n\"Anchoring is a cognitive bias that causes us to rely too heavily on the first\npiece of information we are given about a topic. When we are setting plans or\nmaking estimates about something, we interpret newer information from the\nreference point of our anchor, instead of seeing it objectively.\"\n\nThis is often used in marketing and pricing to delude you into thinking\nsomething is on sale. :')\n\n## 09. Sample Bias\n\nSample bias originates from statistics and is a result of a flawed collection\nof an intended random sample.\n\nThis is particularly common in business and Twitter where people think their\ncustomers or Twitter poll-responders are representative of the entire\npopulation.\n\nThey're not and this can often lead to very poor decision making or conclusions.\n\n## 10. Assignment Bias\n\n[Assignment Bias](https://www.statisticshowto.com/assignment-bias/#:~:text=Assignment%20bias%20happens%20when%20experimental,people%20who%20are%20significantly%20smarter.)\nis similar to Sample Bias in that it is a bias in the sample\nbut is rooted in a broken assignment system. For example, imagine an\nexperimental drug trial where the \"random assignment machine\" (i.e., a machine\nthat assigns things at random) only treated the young and healthy,\nwhile that is a pathological and extreme example it highlights the issue.\n\nBy the way, it turns out that a good \"random\" sample is extremely hard to\ncollect in the real world—ask the Census.\n\n## 11. Self-Selection Bias\n\n[Self-Selection Bias](https://en.wikipedia.org/wiki/Self-selection_bias)\nis another form of sample bias but it's caused by the participants choosing\nwhether or not to participate in the experiment or treatment.\n\nAgain, in the example above imagine instead that the \"random assignment\nmachine\" only treated the people who wanted to be treated and not the\nones that did.\n\nSimilar to the previous case it would ruin the experiment.\n\n## 12. Decision Fatigue\n\n[Decision Fatigue](https://en.wikipedia.org/wiki/Decision_fatigue) is a\nphenomenon whereby an individual's decision making quality deteriorates after a\nlong session of decision making.\n\nIn short, you get tired of making choices and you start to get sloppy. In the\nbusiness and investing world, this is extremely consequential because your or\nyour investor's money is on the line.\n\n## 13. Optimism Bias\n\nTo quote Wikipedia, \"[Optimism Bias](https://en.wikipedia.org/wiki/Optimism_bias)\nis a cognitive bias that causes someone to believe that they themselves are less\nlikely to experience a negative event. It is also known as unrealistic optimism\nor comparative optimism.\"\n\nIt is good to be optimistic but it is *good-er* to balance it in reality.\n\n## 14. Response Bias\n\n[Response Bias](https://en.wikipedia.org/wiki/Response_bias) is both interesting\nand counterintuitive.\n\nIt is catch-all for the frequent tendency of participants to respond\ninaccurately or falsely to survey questions. This is part of the reason surveys\noften conflict with reality.\n\nAs a statistician, I feel surverys are *kind of* useful but behaviors reveal the\ntruth. Measure behaviors.\n\nFor internet companies, you may find that user-survery metrics conflict with\ntracking metrics that you have for your customer. What people say and what they\ndo are often wildly different.\n\n## 15. The Accuracy Paradox\n\nLastly, [The Accuracy Paradox](https://en.wikipedia.org/wiki/Accuracy_paradox)\nis the paradoxical finding that Accuracy isn't necessarily a good metric for for\nmeasuring statistical or machine learning models.\n\nThis is because of an imbalance of outcomes.\n\nSuppose I was trying to predict a whether someone had a rare illness (1\nout of 10,000 people have it), if I predicted everyone didn't have it I'd still\nhave 99.99% accuracy.\n\nSo, accuracy can often be quite useless as a metric for assessing the\nquality of things in general (though not always).\n\n# Managing the Irrational\n\nYou *probably* can't completely stop yourself from irrational decision making\nbut you can *possibly* manage it.\n\nMy approach is simple: acknowledge the biases above, the idiosyncratic ones I have\nfrom my life exeriences, and reflect frequently. I find that this results in me\nchanging my mind often.\n\nThis can be frustrating but I think that early reactions or understandings\nare often not the optimal ones so I try to put effort into reflecting so that I\ncan just do better.\n\n# Some Advice\n\n(this advice may or may not be useful)\n\nBeing objective is nearly impossible when it relates to human judgement, and I'm\nnot even exactly sure what \"objective\" *really* means outside of mathematics.\n\nBut my advice on being as objective as possible is to write things down:\nbullet points, a simple pros and cons list, or whatever suits you can highlight\nflaws in your judgement and reasoning.\n\nI find this brings me mental clarity more than anything else really. I also\ntend to write things down on paper the good ol' fashion way (maybe it's an\nold habit grounded in problem sets, who knows).\n\nManaging cognitive biases and mitigating the adverse consequences they may hold\nis extremely challenging but a well worthy endeavor, as good decisions compound\nlike great investments.\n\nBut don't worry too much if you find yourself struggling with it, we are all\nhuman after all.\n\n-Francisco\n\n","excerpt":""},"previousPost":{"slug":"binary-representation-of-positive-integers","frontmatter":{"title":"Binary Representation of Positive Integers","description":"A tutorial on converting numbers from decimal to binary...and back!","date":"April 2, 2022"},"excerpt":"","content":"\nIt's always fun to learn some additional tricks in math and computer science and I recently started reading about digital representation of numbers and [Swarthmore](https://www.swarthmore.edu/NatSci/echeeve1/Ref/BinaryMath/NumSys.html#:~:text=In%20summary%3A-,bit,numbers%20from%200%20to%20255.) has some truly great material on this.\n\nI was searching around the internet on how to programatically convert decimal numbers to binary and I found there wasn't *that* great of a resource and stackoverflow had mixed stuff so I thought I'd put it something together quickly.\n\nI'll probably add to this tutorial later but I think the code is the most important part.\n\n# The basics\n\nIn short, we want to represent a decimal number (i.e., a number represented in base 10 via the 10 digits we use [0-9]), e.g., 86, as a binary number (i.e., a number represented in base 2 via the 2 digits we are then limited to [0 and 1]).\n\nAs outlined in the tutorial above, this results in the two representations:\n\n$$86_{10} = 1*64 + 0*32 + 1*16 + 0*8 + 1*4 + 1*2 + 0*1$$\n\nand\n\n$$86_{10} = 1*2^6 + 0*2^5 + 0*2^3 + 1*2^2 + 1*2^1 + 0*2^0$$\n\nWhich is equivalent to saying\n\n$$86_{10} = 1010110_2.$$\n\nThe subscript $2$ denotes a binary number. Each digit in a binary number is called a bit. The number 1010110 is represented by 7 bits. Any number can be broken down this way, by finding all of the powers of 2 that add up to the number in question (in this case 26, 24, 22 and 21).\n\nCool.\n\nSo how do we do this with a computer?\n\n# Binary Representation in Python\n\nAs we saw before, representing 86 in binary format requires us to deconstruct it from $2^n$, so with computers we can represent 86 by either recursively dividing by 2 (with some additional adjustment) or iteratively (via a while loop) doing pretty much the same thing. Here's the recursive version:\n\n```python\ndef decimalToBinary(n: int) -\u003e str:\n    if n == 0:\n        return \"\"\n    else:\n        return decimalToBinary(n // 2) + str(n % 2)\n```\n\nThis is pretty simple and could be trivally mapped to a one-liner but for readability I'll say this is sufficient. Alternatively, we could solve this with a while loop using the following:\n\n```python\ndef decimalToBinary2(n: int) -\u003e str:\n    bs = ''\n    while n \u003e 0:\n        r = n / 2\n        n = n // 2\n        bs = str('1' if r % 1 \u003e 0 else '0') + bs\n\n    return bs\n```\n\nAnd this is also pretty simple. It's worth noting that the str() function call is required before concatenating the binary string variable (i.e., bs) because without it python will actually fail to execute the if-else logic and you will not get the behavior you are looking for.\n\n# Decimal Representation from Binary in Python\n\nOkay, so how do we confirm this is behaving correctly? Obviously we can just recover it.\n\n\n```python\ndef binaryToDecimal(bs: str) -\u003e int:\n    n, r = len(bs), 0\n    for i in range(n):\n        r+= int(bs[i]) * 2**(n - i - 1)\n    return r\n```\n\nAnd that's it! If you stare at this formula for a second you'll see it's just taking each bit in the string and multiplying the $i^{th}$ binary value by $2^{n-i-1}$.\n\nWe can verify that all of this works with some simple checks and comparisons:\n\n```python\ndecimalToBinary(86) == decimalToBinary2(86) # 1010110 == 1010110 --\u003e true\nbinaryToDecimal(decimalToBinary2(86)) == 86 # true, converted 1010110 -\u003e 86\n```\n\nHow cool is that?  I'll note that this is only accurate for positive integers but for the general case you can use the first digit to represent the sign of the numbers (with some handling for the 0 edge case).\n\nHope you found this interesting. As I said I'll elaborate more on this post eventually but I thought I mostly wanted to share the code as I didn't really see good examples providing this back and forth and it was something that helped me understand things more concretely.\n\nHappy typing!\n\n-Francisco\n"},"nextPost":{"slug":"difficulties-deploying-ml-models","frontmatter":{"title":"The Difficulties of Deploying a Machine Learning Model","description":"10 lessons from a decaade of deploying machine learning","date":"July 5, 2022"},"excerpt":"","content":"\n\n\u003cblockquote class=\"twitter-tweet\"\u003e\u003cp lang=\"en\" dir=\"ltr\"\u003eyou know, deploying machine learning models is very, very difficult\u003c/p\u003e\u0026mdash; Francisco Javier Arceo (@franciscojarceo) \u003ca href=\"https://twitter.com/franciscojarceo/status/1544110672660807680?ref_src=twsrc%5Etfw\"\u003eJuly 5, 2022\u003c/a\u003e\u003c/blockquote\u003e \u003cscript async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"\u003e\u003c/script\u003e\n\n\n# Some Professional History\n\nI've been working in applied machine learning for nearly 10 years and it's quite exciting\nto have experienced firsthand how much machine learning infrastructure has changed.\n\nI spent the first half of my career as a \"modeler\" where I focused on building\nmachine learning and statistical models for a bunch of different use cases. Over\ntime I found that I migrated more and more to the engineering work to get the model\ndeployed because I always found this to be a bottleneck in the work I did.\n\nConcretely, I'd build a pretty good model that suggested it would be impactful\n(based on expectations of the performance) but I often found it was a rather\nextraordinary effort to get it live and interacting with users/customers.\n\nThis is quite well cited by the data science / MLOps space today but it was\nles obvious back in 2012 and it was very frustrating. The good news is that, for\nbetter or worse, I was rather relentless in getting my models over the finish line.\n\nWhich, in many ways, is what led me to the career I have stumbled into today—which\nI am very grateful for—as an engineering manager working at the intersection of\nmachine learning, data, and engineering.\n\nAll this to say that I have spent a surprising share of the last decade working on\ngetting models into live product experiences. Since I have some lessons learned and\nsome potentially useful opinions, I thought I'd write them down.\n\n# Ten Lessons Learned from a decade of Deploying ML\n\n## 0. Create strict contracts with the input source of your features\n\n## 1. Test your feature engineering more than you want to\n\n## 2. Codify the range and scale of your features\n\n## 3. Separate your model execution from your feature engineering\n\n## 4. Separate matrix serialization from model execution\n\n## 5. Avoid mixing business logic with statistical operations\n\n## 6. Precompute what you can\n\n## 7. Load your model at service build time\n\n## 8. Right size your server\n\n## 9. Monitor your model and features \n"}},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"paradoxes-and-cognitive-biases"},"buildId":"xVXVWxcnuhX3-A_jH0xjr","nextExport":false,"isFallback":false,"gsp":true}</script><script nomodule="" src="/_next/static/chunks/polyfills-fa276ba060a4a8ac7eef.js"></script><script src="/_next/static/chunks/main-39418da170c6bb422e22.js" async=""></script><script src="/_next/static/chunks/webpack-e067438c4cf4ef2ef178.js" async=""></script><script src="/_next/static/chunks/framework.9707fddd9ae5927c17c3.js" async=""></script><script src="/_next/static/chunks/commons.a6f6c255f30e2cc8ab2c.js" async=""></script><script src="/_next/static/chunks/pages/_app-6bd4657ff7c26af8364b.js" async=""></script><script src="/_next/static/chunks/5e7de4f36e438e169c5d145e7df90137ae956f1e.c55db21543619f2e3353.js" async=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-f7cba0a36d81c7b5f6f1.js" async=""></script><script src="/_next/static/xVXVWxcnuhX3-A_jH0xjr/_buildManifest.js" async=""></script><script src="/_next/static/xVXVWxcnuhX3-A_jH0xjr/_ssgManifest.js" async=""></script></body></html>