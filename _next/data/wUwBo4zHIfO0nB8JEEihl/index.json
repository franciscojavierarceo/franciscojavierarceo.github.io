{"pageProps":{"posts":[{"slug":"data-science-and-fintech","frontmatter":{"title":"Data Science and Fintech","description":"How Data Science Scaled the Fintech Revolution","date":"January 22, 2021"},"excerpt":"","content":"\nI've spent the last 10 years working in data science, mostly in Fintech and it's been really exciting to have seen how data science, engineering, and the internet has reshaped all aspects of finance.\n\n[Others have written before](https://fintechtoday.substack.com/p/part-1-what-is-fintech-30-anyway) about how Fintech has evolved from 0.0 to 3.0 over the last decade and one area that I think is interesting is how data science and analytics has helped fuel that growth.\n\n>So, how ***exactly*** has data science helped scale fintech?\n\nI think data science has scaled fintech in five key areas.\n\n## 1. Operations\n\nThe market tends to have a preference for technology companies because of the operational efficiencies that come from technology's scale. Simply put, data scientists help identify data and processes that can be automated to help achieve better operational efficiency.\n\nA concrete Fintech example of this is fraud operations. If you're a bank with a credit card product, manually reviewing even 10% of your credit card transactions would be an impossible task (it's been [cited](https://www.marketwatch.com/story/why-bitcoin-wont-displace-visa-or-mastercard-soon-2017-12-15) that Visa and Mastercard process 5,000 transactions per second).\n\nSo, in this circumstance data scientists will build models to reduce the amount of review needed through predictive models.\n\n## 2. Marketing\n\nIn Fintech, Customer Acquisition Cost (CAC) is everything. Others have written about [CAC and Fintech](https://medium.com/unifimoney/the-no-cac-bank-5e0e577d5473) in greater depth, but suffice it to say it is a challenging and competitive problem.\n\nData scientists focused on marketing try to reduce CAC through a wide variety of strategies.\nSome of them are by tightly monitoring product metrics to see which features yield the best ROI on growth, while other approaches take a broader lense by trying to take a comprehensive view of your marketing investments and, again, optimizee the expected return (e.g., through [Marketing Mix Models](https://blog.hurree.co/blog/marketing-mix-modeling)).\n\nOther approaches are more focused on [\"propensity models\"](https://medium.com/the-official-integrate-ai-blog/heres-what-you-need-to-know-about-propensity-modeling-521ab660cb43) and trying to maximize customer engagement or acquisition. Sometimes this involves building propensity models to convert a customer from an email subscriber to a fully-converted user (e.g., for a lending product or a mobile application), while other propensities may focus on simply getting a customer to re-engage with your product.\n\n## 3. Risk Management\n\nThis is where I've spent most of my career and I think it's a really hard problem that most fintechs struggle with in the lending space.\nGenerally speaking, data scientists will build risk models (e.g., for credit risk or fraud risk) to predict the probability of default or some likelihood of delinquency ([more on the difference between them](https://www.investopedia.com/ask/answers/062315/what-are-differences-between-delinquency-and-default.asp)).\n\nBuilding good predictive models is hard. Building good *risk* models is extremely hard.\n\nThis is less because of a technology or data problem and more because of regulatory checks and balances in place. Making sure that you adhere to [FCRA](https://www.ftc.gov/enforcement/statutes/fair-credit-reporting-act) and [ECOA](https://uscode.house.gov/view.xhtml?req=granuleid%3AUSC-prelim-title15-chapter41-subchapter4&edition=prelim) and other regulatory oversight is hard on its own, adding statistical analysis into the mix makes it even harder.\n\nImplementation (i.e., getting an algorithm in production that impacts your customers) of these models is a whole other area of data science and one of the areas I personally find quite fun (maybe I'll write more abou this topic later).\n\n## 4. Technology\n\nData scientists often work with engineering/technology teams in order to improve the technology stack. This may involve changing an architecture to reducy latency of certain services or enhancing the curent stack for a unique problem (cue machine learning and [Airflow DAGs](https://airflow.apache.org)).\nWhile some of this is behind the scenes, it can be some of the most impactful work done by a data scientist in the fintech space because of the broader impact of the items mentioned above.\n\n## 5. Customer Experience\n\nData scientists working with product teams are often tasked with measurement of different experiences within the product and finding out ways to enhance it. That can vary from creating dashboards to monitoring the right metrics to building a recommendation system to curate something specific for a user. Data scientists can fuel product growth, which is why [Facebook, Google, Amazon, Microsoft](https://www.datasciencedegreeprograms.net/lists/five-of-the-largest-companies-that-employ-data-scientists/) and other tech companies hire so many data scientists.\n\nI'll probably write more technical examples of each one of these to give a more concrete information with code and diagrams but I wanted to keep this post high-level to introduce the topics.\n\nSo, to summarize, data scientists are useful (particularly in Fintech) when there are hard problems and data available to solve them.\n\n***\nHave some feedback? Feel free to [let me know](https://twitter.com/franciscojarceo)!"},{"slug":"ordinary-least-squares","frontmatter":{"title":"Ordinary Least Squares","description":"A brief note about the most important equation in all of statistics.","date":"January 14, 2021"},"excerpt":"","content":"\nOne of my favorite authors and historical statisticians [Dr. Stephen Stigler](https://stat.uchicago.edu/people/profile/stephen-m.-stigler/) published a wonderful historical review in 1981 titled [*Gauss and the Invention of Least Squares*](https://projecteuclid.org/download/pdf_1/euclid.aos/1176345451). He argued that the prolific [Carl Freidrich Gauss](https://en.wikipedia.org/wiki/Carl_Friedrich_Gauss) discovered [Ordinary Least Squares](https://en.wikipedia.org/wiki/Least_squares) (OLS) in 1809 and fundamentally shaped the future of science, business, and society as we know it.\n\nSo, what is OLS and why is it so important?\n\nOLS is often referred to by many things across several different discipilines, some of them are:\n\n- Linear Regression\n- Multivariate Regression\n- The Normal Equations\n- Maximum Likelihood\n- Method of Moments\n- Singular Value Decomposition of $\\bf{X}\\bf{w}-\\bf{y}=U(\\Sigma'\\bf{w}-U'-\\bf{y})$\n\nBut all of them ultimately reflect the same mathematical expression (in scalar notation):\n\n$$y_i = \\beta_0 + \\sum_{j=1}^{k} \\beta_i x_i + \\epsilon_i$$\n\nWhich yields the famous estimator (i.e., equation) for $\\hat{\\beta_j}$ as\n\n$$\\hat{\\beta_j} = \\sum_{i=1}^{n} (x_i - y_i)^2 / \\sum_{i=1}^n (x_i - \\bar{x})^2$$\n\nOr in matrix notation:\n\n$$\\bf \\hat{\\beta} = \\bf (X'X)^{-1} X'Y$$.\n\nI find this simple equation to be so extraordinary.\n\nWhy? Because of what can be learned from it: the equation basically says \"Look at data about $\\bf{x}$ and estimate a linear relationship to $\\bf{y}$\". \n\nAs a concrete example, imagine you wanted to know the relationship between age and income (a simplification of the well-studied [Mincer Equation](https://en.wikipedia.org/wiki/Mincer_earnings_function)), how would you figure this out? A simple linear regression could estimate that relationship and the $\\hat{\\beta}$ would represent the partial-correlation (sometimes called the marginal effect or coefficient estimate) and it exactly represents the slope of the line below.\n\n![A scatter plot!](scatterplot.png)\n<p align=\"center\" style=\"padding:0\"><i>A Scatter Plot of Age and Income</i></p>\n\nIsn't that just amazing??\n\nThis single expression is used to estimate models for movie recommendations, businesses, pharmaceuticals, and even decisions about public health. I am constantly amazed at how one little equation could accomplish so much.\n\nTo think Gauss had discovered OLS as a method of calculating the orbits of celestial bodies and that today, over 200 years later, humans would use it to for so much of what we do is astounding.\n\nOver the years statisticians, economists, computer scientists, engineers, and psychometricians have advanced OLS in such profound and unique ways. Some of them have been used to reflect data generated from more non-standard distributions (e.g., a [Weibull distribution](https://en.wikipedia.org/wiki/Weibull_distribution)), or to frame the problem to use prior information in a structured way (e.g., through [Bayesian Inference](https://en.wikipedia.org/wiki/Bayesian_inference)), while others have enhanced these equations to learn high-dimensional non-linear relationships (e.g., via [Artificial Neural Networks](https://en.wikipedia.org/wiki/Artificial_neural_network)). Again, all of these are extended from the extraordinary work of Gauss.\n\nThere's so much that can be written about all of the advancements that have been made in all of these fields and a short blog post simply won't do it justice, but I thought I'd at least share some thoughts about it.\n\nSomewhere along the way today I came across something related to important equations and it led me to write this, so I hope you enjoyed it. \n\nI'm such a fan of the history of statistics and mathematics that this piece, while not as structured as I'd like, was very enjoyable to write.\n\nHappy computing!\n\n-Francisco"},{"slug":"2021-goals","frontmatter":{"title":"Goals for 2021","description":"Sharing some of my goals for 2021","date":"January 9, 2021"},"excerpt":"","content":"\n[I previously wrote about 2020](https://franciscojavierarceo.github.io/post/learning-new-things) and I found that reflecting about the chaos of this past year was rather cathartic for me.\n\nWhile I feel lucky to have endured the pandemic without contracting COVID or suffering job losses, it has been quite isolating. I know that I'm not alone in feeling that and we're all getting through this in our own ways. Regardless, I found that writing my thoughts out loud was helpful, so I suppose I'll continue writing for now.\n\nSince I'm going to try to write more I figured I'd share some of my goals for the new year; so, here are my foolish high-level goals in some unknown order:\n\n1. Be a better husband\n2. Talk less, listen more\n3. Cook more intentionally\n4. Speak more intentionally\n5. Help others more effectively\n6. Write at least 2x per month\n7. Exercise ~5x per week\n\nI hope I'm able to accomplish these. With the exclusion of the last two, these goals aren't particularly measurable (I'll probably find a way to measure them) but I hope to make a good effort. I hope to look back here and attempt to hold myself accountable. Maybe I'll provide an update in June, who knows.\n\nMore specific goals that I have that are much more technical in nature are:\n- Connecting Django Rest Framework (DRF) and React while handling data and localization complexities;\n- Deploying a React Native application to both app stores;\n- Putting in some more hours on Airflow / Cloud Composer;\n- Learning how to train my recommendation models on Kubernetes.\n\nThese will be interesting and I'm making progress on DRF and React but I still have quite a bit of work to do.\n\nHopefully this year will be better, I'm optimistic about it."},{"slug":"i-love-code","frontmatter":{"title":"I Love Code","description":"Some thoughts on the elegance of code.","date":"January 6, 2021"},"excerpt":"","content":"\nI love code. Plain and simple.\n\nI didn't always though. I started programming at 21 years old during my first masters---I was studying statistics and used code only as a means for running regression models and doing microeconometrics research. I started statistical programming back in 2011 using [STATA](https://www.stata.com/) and [SAS](https://www.sas.com/). They weren't *real* programming languages by a computer scientist's standards but that is technically how I started.\n\nI eventually moved onto to learning [SQL](https://en.wikipedia.org/wiki/SQL) and [R](https://www.r-project.org/about.html) when I started working and I found myself often writing Monte Carlo simulations of harmonic regressions, two stage least-squares, and other machine learning/statistical phenomenon.\n\nAnd that's how it started. I began learning [Python](https://www.python.org/) more actively at work and it mostly increased from there. During my second masters I started learning [Lua](http://www.lua.org/) in order to use [Torch](http://torch.ch/), which was used by [facebook AI](https://ai.facebook.com/) before [PyTorch](https://pytorch.org/) was developed. Then at Goldman I had to learn proprietary tools like Slang. Now I've spent the last year learning much more about [JavaScript](https://www.javascript.com/) and web development in general, and I just couldn't help but reflect and think about how much I actually *enjoy* it.\n\nIt's 2021 now and it's officially beeen a 10 year journey learning how to code (although what can only be argued as chaotically and poorly across different disciplines). Back when I first started I had no idea how anything in a computer worked and I was really, really bad at it. \n\nIt was miserable and I always felt deeply insecure about my code. I feel lucky now that I'm no longer code-shy and I don't struggle as much as I used to. That's not to say I don't have typos or bugs (I do!) but it's more to say that it's much easier these days for me to read through and understand how things are working and how to debug.\n\nBut that took me 10 years and it was a literal headache for most of the time. I'm curious to see what I'll feel in 10 years and what else I'll have learned.\n\nAll that just to show this beautiful piece of code, which is *a* way to write a function which takes as input *n* and yields its [Fibonacci Number](https://en.wikipedia.org/wiki/Fibonacci_number).\n\n```python\ndef f(n: int) -> int:\n    assert n>0, 'n > 0'\n    if n < 3:\n        return {1:0, 2:1}[n]\n    return f(n-1) + f(n-2)\n```\n\nWhich simply encodes $F_n = F_{n-1} + F_{n-2} \\forall n > 1$, where $F_1 = F_2 = 1$.\n\nThis code is both brief *and* elegant. That's what I love about it. In 5 little lines so much of human collaboration and information is represented. To think that 5 little lines could do all of that is astounding to me, I genuinely find it beauitful. I guess that's because I just love code."},{"slug":"github-actions","frontmatter":{"title":"Deploying a Next.js Site using Github Actions","description":"GitHub Actions to Deploy a Static Site built with Next.js","date":"January 3, 2021"},"excerpt":"","content":"\nI'm a huge fan of [GitHub Actions](https://github.com/features/actions). They're so simple but so effective at doing such a broad range of things. In short, you can tell GitHub do something on a computer everytime you push to your repository (or to a branch on a specific repository like the `main` branch).\n\nFor today's post, I'll focus on how I used an action to automate deploying my static site built with Next.js to [GitHub Pages](https://pages.github.com).\n\nI made this blog on a repository hosted on GitHub and added a GitHub Action to compile the JavaScript/React code into static HTML files. This really didn't require all that much effort.\n\n\nHere's what I had to do:\n\n1. Build a Next.js blog following the [detailed tutorial](https://nextjs.org/learn/basics/create-nextjs-app) and store the code on a GitHub repository\n2. Create a workflow file in the repository with the following path: [**./github/workflows/integrate.yml**](https://github.com/franciscojavierarceo/franciscojavierarceo.github.io/blob/main/.github/workflows/integrate.yml)\n3. Specify that workflow file to export the static files whenever I push to **main** and *commit* the exported files to a separate branch called **gh-pages** (you can just follow the workflow file I used)\n4. Manually add a **.nojekyll** file to the **gh-pages** branch (this is to resolve [this bug](https://github.com/vercel/next.js/issues/2029))\n5. Configure my repository Settings so that it sources the GitHub Pages build from the **gh-pages** branch\n\nAnd that's it, adding new blog posts is as simple as creating a new [markdown](https://www.markdownguide.org/) file and pushing to the **main** branch. The GitHub Action will handle all of the rest!\n\nThis is much nicer in behavior than my old site, which was built using Jekyll (a Ruby framework) and it's much less work than building a full application with Django to get high quality page loads. I’d add that I’m a huge fan of Django but I think for a static, fast, and lightweight site, Next.js my new go to!"},{"slug":"next-js-blog","frontmatter":{"title":"Learning Next.js","description":"Learning the Next JavaScript Framework","date":"January 2, 2021"},"excerpt":"","content":"\nIn the spirit of my last blog post talking about learning new things, I decided to learn <a href=\"https://nextjs.org/\">Next.JS</a>, which is a JavaScript framework built on top of <a href=\"https://reactjs.org/\">React</a> for web development. One of the main reasons I was particularly interested in Next.JS was because of it's opinionated optimizations.\n\nIn my last post I mentioned that I spent a lot of time learning about the technical details of Search Engine Optimization (SEO) and trying to optimize my Django application for that. I was ultimately reasonably successful in it but much of the logic to do so was tedious to author and rather unpleasant, which is why I'm excited about Next.JS, since it automates much of this for you right out of the box.\n\nTo learn it, I built this blog using their <a href=\"https://nextjs.org/learn/basics/create-nextjs-app\">tutorial</a>, which I highly recommend!\n\nMy goal is to move <a href=\"https://www.unidosfin.com/en\">Unidos</a> to Next.JS for the front-end and keep the Django back-end, much of which I've already converted to APIs."},{"slug":"learning-new-things","frontmatter":{"title":"2020 & Learning New Things","description":"Francisco's 2020 Year in Review","date":"January 1, 2021"},"excerpt":"","content":"\n2020 was a **difficult year for most people**, this was true for me as well. Fortunately, along the way I was able to learn some new things. More specifically, I spent a lot of my time learning how to develop web applications (particularly in <a href=\"https://www.djangoproject.com/\">Django</a>), which included:\n\n- Building a Content Management System (<a href=\"https://en.wikipedia.org/wiki/Content_management_system\">CMS</a>)\n- Image optimization and various forms of cacheing\n- User authentication and security best practices (e.g., two factor authentication)\n- Developing APIs using Django Rest Framework\n- The benefits of JavaScript code compression/minification\n- How to adhere to SEO best practices for web content\n- Building Webhooks for 3rd party APIs\n- Building an application that handles multiple languages in a database, as an API, and that optimizes for SEO\n\nIt has been an interesting exercise to be much more hands on with JavaScript this past year, especially since my expertise is mainly in Python. As a data scientist, it's interesting to learn how the web is developed and how data is created from the web.\n\nIn statistics, the Data Generating Process (<a href=\"https://en.wikipedia.org/wiki/Data_generating_process\">DGP</a>) is an extremely critical part of approximating the world with mathematical functions. So, I wanted to learn very rigorously how the web is developed so that I could better understand the DGP and ultimately better approximate the things I'm particularly interested in.\n\nAs an entrepreneur this is a *terrible* way to allocate one's attention in order to accomplish one's business goals, but the knowledge I've gained over the year has been *extremely* valuable and it compounds significantly. I think the knowledge investment I've made this past year has better helped me prepare for much faster growth going forward.\n\nWhat I've learned over the past 10 years is that investing in learning has exponential rewards, especially in time. Things that used to take me days or hours to accomplish can now be solved in minutes.\n\nSo, while my business didn't thrive this year, I do think I have learned a significant amount of information and that's invaluable.\n\nHere's to hoping 2021 is more balanced on learning and execution. I'll try to write a little more frequently about some of the things I'm learning, so I hope you find it interesting."}]},"__N_SSG":true}