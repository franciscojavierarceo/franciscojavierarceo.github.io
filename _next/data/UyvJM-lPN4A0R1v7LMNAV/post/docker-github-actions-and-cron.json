{"pageProps":{"frontmatter":{"title":"Github Actions, Docker, and the Beloved Cron","description":"Using GitHub Actions to run a Python script inside of a docker container scheduled daily.","date":"March 14, 2021"},"post":{"content":"\nI've written before about my love for [Github Actions](https://franciscojavierarceo.github.io/post/github-actions) and [Docker](https://franciscojavierarceo.github.io/post/docker-for-data-science).\n\nA little over a week ago I tweeted that I was interested in writing a blog post about using Github Actions and Docker to schedule a job to do something interesting, but I didn't have a fun use case. \n\nFortunately, my internet friends delivered.\n\n<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">text me with a pic of your dog</p>&mdash; Camilo (@camdotbio) <a href=\"https://twitter.com/camdotbio/status/1367856131972947972?ref_src=twsrc%5Etfw\">March 5, 2021</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n\nSo I decided to write a quick script to do this, and that's how I spent my Friday evening as my wife and I watched Avengers. 😂\n\nI've provided a link to the [Github Repository](https://github.com/franciscojavierarceo/twitter-cron-demo) with the full code but here's the short instructions if you're interested.\n\n## 1. Register for a developer account on [Twitter](https://developer.twitter.com/en/apply-for-access) and get your API credentials\n\nThis is a pretty easy process and you just sign up and outline what you're doing (it's also free). Note that you'll need to store 4 variables in a `.env` file like below:\n\n    TWITTER_API_KEY=\n    TWITTER_API_SECRET=\n    TWITTER_ACCESS_TOKEN=\n    TWITTER_ACCESS_TOKEN_SECRET=\n\n## 2. Write a Python Script to Tweet a Dog Photo\n\nThis was pretty straightforward thanks to the [Tweepy](https://www.tweepy.org) library in Python and this super random [dog photo API](https://dog.ceo/dog-api/) (God bless the internet).\n\nHere's what that Python code looks like:\n\n```python\nimport os\nimport json\nimport requests\nimport tweepy\n\ndef get_random_dog(filename: str='temp') -> None:\n    r = requests.get('https://dog.ceo/api/breeds/image/random')\n    rd = json.loads(r.content)\n    r2 = requests.get(rd['message'])\n\n    with open(filename, 'wb') as image:\n        for chunk in r2:\n            image.write(chunk)\n\ndef main(message: str, filename: str='temp') -> None:\n    auth = tweepy.OAuthHandler(\n        os.environ.get('TWITTER_API_KEY'), \n        os.environ.get('TWITTER_API_SECRET')\n    )\n    auth.set_access_token(\n        os.environ.get('TWITTER_ACCESS_TOKEN'), \n        os.environ.get(\"TWITTER_ACCESS_TOKEN_SECRET\")\n    )\n    api = tweepy.API(auth)\n    get_random_dog(filename) \n\n    try:\n        api.verify_credentials()\n        print(\"Twitter Authentication Succeeded\")\n    \n        try:\n            api.update_with_media(filename, status=message)\n            print('Tweet successfully sent!')\n\n        except Exception as e:\n            print('Error sending tweet \\n %s' % e)\n    except:\n        print(\"Twitter Authentication Failed\")\n\n\nif __name__ == '__main__':\n    main(\"Hey, @camdotbio! 👋 \\n\\nHere's your daily dog photo!\")\n```\n\n## 3. Create a Docker Container to run the Python Script \n\nThis is a contentious area where some may argue docker is execessive for this but I use different computers with different operating systems so this works for me and I like it. \n\nIn short, I created a [Dockerfile](https://github.com/franciscojavierarceo/twitter-cron-demo/blob/main/Dockerfile) and a [docker-compose](https://github.com/franciscojavierarceo/twitter-cron-demo/blob/main/docker-compose.yml) file where I run the script. The benefit of this is that I don't have to worry about this script not working on my Linux machine or not working on my Mac, it works on both!\n\n## 4. Use a Github Action to Schedule a Cron Job\n\nThis was also straightforward and I've copied the code below:\n\n```yml\nname: Build and Deploy 🚀\n\non:\n    schedule:\n        - cron: '0 15 * * *'\n\njobs:\n    build:\n        runs-on: ubuntu-latest\n\n        steps:\n            - uses: actions/checkout@v2\n\n            - name: Make envfile\n              uses: SpicyPizza/create-envfile@v1\n              with:\n                  envkey_TWITTER_API_KEY: ${{ secrets.TWITTER_API_KEY }}\n                  envkey_TWITTER_API_SECRET: ${{ secrets.TWITTER_API_SECRET }}\n                  envkey_TWITTER_ACCESS_TOKEN: ${{ secrets.TWITTER_ACCESS_TOKEN }}\n                  envkey_TWITTER_ACCESS_TOKEN_SECRET: ${{ secrets.TWITTER_ACCESS_TOKEN_SECRET }}\n                  file_name: .env\n\n            - name: Build the docker container\n              run: docker build .\n\n            - name: Run the script 🚀\n              run: docker-compose up\n```\nNote that you have to create [Action Secrets](https://docs.github.com/en/actions/reference/encrypted-secrets) in your Github Repository (available in the Settings tab) and add the credentials from Step 1.\n\n## Conclusion \n\nAnd that's it! 🐶 \n\nPushing the code to GitHub handles the rest, isn't that wonderful?\n\nAnyways, thanks to my internet friends for the fun idea. I didn't end up sending it to Camilo's phone number because I would have to pay Twilio $0.0075.\n\n---\n*Have some feedback? Feel free to [let me know](https://twitter.com/franciscojarceo)!*","excerpt":""},"previousPost":{"slug":"function-approximation","frontmatter":{"title":"Function Approximation using Data Science Techniques","description":"A Data Scientist's guide to Function Approximation","date":"February 21, 2021"},"excerpt":"","content":"\n# Regression\n\nI've written about the wonders of [Linear Regression](https://franciscojavierarceo.github.io/post/ordinary-least-squares) before and one of the things I find most amazing about it is that it allows you to approximate a function.\n\n> But what does that mean?\n\nIn short, take data about two things and estimate a relationship between them.\n\nA classic example is Age and Income. \n\nSuppose you wanted to understand how a person's age *correlates* to their income. You could take a sample of data and store it in a table, spreadsheet, or even a fancy database somewhere so you could analyze it.\n\nYou could then draw a scatter plot (like below) and *visualize* the relationship between the two attributes and fit (i.e., estimate) the relationship (i.e., the slope of that line). If the relationship was strictly **linear**, we'd see a scatter plot that looks something like the graph below.\n\n![A scatter plot!](scatterplot.png)\n<p align=\"center\" style=\"padding:0\"><i>A Scatter Plot of Age and Income with a Linear Relationship</i></p>\n\nBut what if it wasn't linear?\n\nWhat if we knew Age only increased Income to a degree and that the marginal return was decreasing? Well, maybe we'd see a plot like below.\n\n![A scatter plot!](income_age_squared.jpeg)\n<p align=\"center\" style=\"padding:0\"><i>A Scatter Plot of Age and Income with a Quadratic Relationship</i></p>\n\nWhat if things were a little less intuitive and, after another point, your Income (on average) started to go back up again? We'd see the graph below.\n\n![A scatter plot!](income_age_cubic.jpeg)\n<p align=\"center\" style=\"padding:0\"><i>A Scatter Plot of Age and Income with a Cubic Relationship</i></p>\n\nLastly, what if we saw something that was just plain *weird*?\n\n![A scatter plot!](income_age_weird.jpeg)\n<p align=\"center\" style=\"padding:0\"><i>A Scatter Plot of Age and Income with a Piecewise Linear, Discontinuous Function</i></p>\n\nThis is my favorite example because it shows a [piece-wise linear function](https://en.wikipedia.org/wiki/Piecewise_linear_function) and, while strange looking, these relationships are very common phenomena in the wild.\n\nWhy?\n\nBecause often times we are modeling behaviors or decisions by other systems in the world, and those systems, decisions, and behaviors often have weird boundary points/thresholds. In the credit world, you'll often see this because a lender's credit policy systematically rejects applications with a certain set of criteria, which would lead to visualizations identical to this.\n\n## What do we do with all of this information?\n\nThis is the fun part! \n\nIf you're doing data science and modeling data with lots of features/attributes, you probably don't want to do this for hundreds or thousands of different variables. Instead, you may benefit from finding a way to estimate the univariate relationship algorithmically. \n\nBut how?\n\nWhen you have a bivariate relationship like this you don't want to have to tediously [engineer features](https://en.wikipedia.org/wiki/Feature_engineering) to estimate the underlying function, rather you'd prefer to have a machine learn (or estimate) the function using [supervised learning](https://en.wikipedia.org/wiki/Supervised_learning).\n\nBut which algorithm and how do I use it? Well, there are a few options people typically use:\n\n- [Polynomial Regression](https://en.wikipedia.org/wiki/Polynomial_regression)\n- [Multivariate Adaptive Regression Splines (MARS)](https://en.wikipedia.org/wiki/Multivariate_adaptive_regression_spline)\n- [Decision Trees](https://en.wikipedia.org/wiki/Decision_tree_learning)\n- [Weight of Evidence](https://documentation.sas.com/?cdcId=pgmsascdc&cdcVersion=9.4_3.3&docsetId=casstat&docsetTarget=casstat_binning_details03.htm&locale=en)\n\nAnd each has its own unique benefits.\n\nBut my personal favorite is MARS. If we used R's [earth package](https://cran.r-project.org/web/packages/earth/earth.pdf) we can estimate this function automatically in a few simple lines of code and get the predicted fit below.\n\n![A scatter plot!](income_age_mars.jpeg)\n<p align=\"center\" style=\"padding:0\"><i>A Scatter Plot of Age and Income using Function Approximation</i></p>\n\nAnd here's the R code to generate it.\n\n```R\nlibrary(earth)\nearth.mod <- earth(income ~ age, data = df)\nplotmo(earth.mod)\nprint(summary(earth.mod, digits = 2, style = \"pmax\"))\ndft$preds <- predict(earth.mod, df)[,1]\n```\n\nShort, sweet, and effective—my favorite combination. \n\nThe other algorithms all have pros and cons, and I largely recommend to use each one depending on how smooth or *not*-smooth the underlying behavior of your data is (and how much you care to really account for it). \n\nAnyways, I hope you liked this post; it was a very enjoyable excuse for me to make some graphs.\n\n*Have some feedback? Feel free to [let me know](https://twitter.com/franciscojarceo)!*"},"nextPost":{"slug":"toxic-bert-and-fast-api","frontmatter":{"title":"Bert Transformers, FastAPI, and Toxic Twitter","description":"A Data Scientist's Guide to using FastAPI and BERT to Build a twitter scanner of your tweets.","date":"April 11, 2021"},"excerpt":"","content":"\n## I will write less frequently\n\nUnfortunately, I've been writting a little less frequently than I was hoping to this year; I was targetting about once a week but I think that was (1) a little too frequent and (2) a little too ambitious of me to think I'd be able to keep up that pace.\n\n## I will write more quality\n\nI'll aim to write once or a month or so and hope for higher quality posts. \n\nIn the spirit of more interesting content (and more interesting problems for me to tinker with) in the Twitter thread below I decided I'd write a blog post on building a webtool that scans a user's historical tweets and identifies the highest risk ones.\n\n<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">Is there an ML type service that can plow through history for potentially problematic tweets?</p>&mdash; Matt Galligan (@mg) <a href=\"https://twitter.com/mg/status/1372923621040082944?ref_src=twsrc%5Etfw\">March 19, 2021</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n\nI decided to work on this because (1) it's at the intersection of things I really enjoy (nlp, web development, and twittter), (2) I wanted to build a tool that would solve a real problem, and (3) I thought it'd be fun.\n\n## Creating a Toxic Twitter Scanner\n\nI think this tool can be broken down into 3 sub-problems:\n1. Creating a web service to handle the front-end user experience (authentication and rendering of data)\n2. Creating a machine learning model as an endpoint that handles predicting the toxicity/problematicness of a user's tweets\n3. Connecting (1) and (2) and deploying them as a service in an automated way\n\nThere's a bunch of stuff in between and technical things to handle, but this is really what I think matters at a high-level, so let's dive in!\n\n### 1. Creating a Web Service\nAs a web tool, a user should be able to authenticate with Twitter to scan their tweets and consent to the service using their data (this is to access private tweets). As a starting point, I'll probably launch this tool without any authentication and just look at a user's public tweets.\n\n### 2. Creating a Machine Learning model as an API\nThis is a reasonably straightforward process as the endpoint will be a wrapper around an existing machine learning library and the goal is to be able to send in some data and get some scores back.\n\n### 3. Connecting a Web Service to an ML API\nThis is an important step. In summary, we want to decouple the user-facing experience from the machine learning because they have very different technical requirements. The compute cluster that'll create predictions for the tweets will use much more memory than the user-facing application, so it's important to separate them so computing doesn't slow down the user experience.\n\n## Progress on Building a Scanner\n\nSo far I've been diving into using a pre-trained BERT model developed by [Laura Hanu](https://laurahanu.github.io) at [Unitary](https://www.unitary.ai) and it's been pretty fun. I've been able to score my own tweets and see the behavior of this model and see various implementation details that I'll have to be mindful of (I'll probably write more on this later).\n\nI've been tinkering with [FastAPI](https://fastapi.tiangolo.com) and figuring out how the [cookie-cutter template](https://fastapi.tiangolo.com/project-generation/) works. I don't love the way it behaves and there's a lot of strong opinions in place which is helpful but imperfect; we'll see how my opinion shapes as I spend more time with it.\n\nI'm very excited to learn [Docker Swarm](https://docs.docker.com/get-started/swarm-deploy/) as it seems like a very promising framework for deploying the model API.\n\nYou can follow my progress on this [GitHub repository](https://github.com/franciscojavierarceo/twitter-scan). Stay tuned as I'll be updating this blog with my thoughts as I chip away at this problem.\n\n---\n*Have some feedback? Feel free to [let me know](https://twitter.com/franciscojarceo)!*\n"}},"__N_SSG":true}