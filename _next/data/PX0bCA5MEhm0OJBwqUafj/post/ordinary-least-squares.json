{"pageProps":{"frontmatter":{"title":"Ordinary Least Squares","description":"A brief note about the most important equation in all of statistics.","date":"January 14, 2021"},"post":{"content":"\nOne of my favorite authors and historical statisticians [Dr. Stephen Stigler](https://stat.uchicago.edu/people/profile/stephen-m.-stigler/) published a wonderful historical review in 1981 titled [*Gauss and the Invention of Least Squares*](https://projecteuclid.org/download/pdf_1/euclid.aos/1176345451). He argued that the prolific [Carl Freidrich Gauss](https://en.wikipedia.org/wiki/Carl_Friedrich_Gauss) discovered [Ordinary Least Squares](https://en.wikipedia.org/wiki/Least_squares) (OLS) in 1809 and fundamentally shaped the future of science, business, and society as we know it.\n\nSo, what is OLS and why is it so important?\n\nOLS is often referred to by many things across several different discipilines, some of them are:\n\n- Linear Regression\n- Multivariate Regression\n- The Normal Equations\n- Maximum Likelihood\n- Method of Moments\n- Singular Value Decomposition of $\\bf{X}\\bf{w}-\\bf{y}=U(\\Sigma'\\bf{w}-U'-\\bf{y})$\n\nBut all of them ultimately reflect the same mathematical expression (in scalar notation):\n\n$$y_i = \\beta_0 + \\sum_{j=1}^{k} \\beta_i x_i + \\epsilon_i$$\n\nWhich yields the famous estimator (i.e., equation) for $\\hat{\\beta_j}$ as\n\n$$\\hat{\\beta_j} = \\sum_{i=1}^{n} (x_i - y_i)^2 / \\sum_{i=1}^n (x_i - \\bar{x})^2$$\n\nOr in matrix notation:\n\n$$\\bf \\hat{\\beta} = \\bf (X'X)^{-1} X'Y$$.\n\nI find this simple equation to be so extraordinary.\n\nWhy? Because of what can be learned from it: the equation basically says \"Look at data about $\\bf{x}$ and estimate a linear relationship to $\\bf{y}$\". \n\nAs a concrete example, imagine you wanted to know the relationship between age and income (a simplification of the well-studied [Mincer Equation](https://en.wikipedia.org/wiki/Mincer_earnings_function)), how would you figure this out? A simple linear regression could estimate that relationship and the $\\hat{\\beta}$ would represent the partial-correlation (sometimes called the marginal effect or coefficient estimate) and it exactly represents the slope of the line below.\n\n![A scatter plot!](scatterplot.png)\n<p align=\"center\" style=\"padding:0\"><i>A Scatter Plot of Age and Income</i></p>\n\nIsn't that just amazing??\n\nThis single expression is used to estimate models for movie recommendations, businesses, pharmaceuticals, and even decisions about public health. I am constantly amazed at how one little equation could accomplish so much.\n\nTo think Gauss had discovered OLS as a method of calculating the orbits of celestial bodies and that today, over 200 years later, humans would use it to for so much of what we do is astounding.\n\nOver the years statisticians, economists, computer scientists, engineers, and psychometricians have advanced OLS in such profound and unique ways. Some of them have been used to reflect data generated from more non-standard distributions (e.g., a [Weibull distribution](https://en.wikipedia.org/wiki/Weibull_distribution)), or to frame the problem to use prior information in a structured way (e.g., through [Bayesian Inference](https://en.wikipedia.org/wiki/Bayesian_inference)), while others have enhanced these equations to learn high-dimensional non-linear relationships (e.g., via [Artificial Neural Networks](https://en.wikipedia.org/wiki/Artificial_neural_network)). Again, all of these are extended from the extraordinary work of Gauss.\n\nThere's so much that can be written about all of the advancements that have been made in all of these fields and a short blog post simply won't do it justice, but I thought I'd at least share some thoughts about it.\n\nSomewhere along the way today I came across something related to important equations and it led me to write this, so I hope you enjoyed it. \n\nI'm such a fan of the history of statistics and mathematics that this piece, while not as structured as I'd like, was very enjoyable to write.\n\nHappy computing!\n\n-Francisco","excerpt":""},"previousPost":{"slug":"2021-goals","frontmatter":{"title":"Goals for 2021","description":"Sharing some of my goals for 2021","date":"January 9, 2021"},"excerpt":"","content":"\n[I previously wrote about 2020](https://franciscojavierarceo.github.io/post/learning-new-things) and I found that reflecting about the chaos of this past year was rather cathartic for me.\n\nWhile I feel lucky to have endured the pandemic without contracting COVID or suffering job losses, it has been quite isolating. I know that I'm not alone in feeling that and we're all getting through this in our own ways. Regardless, I found that writing my thoughts out loud was helpful, so I suppose I'll continue writing for now.\n\nSince I'm going to try to write more I figured I'd share some of my goals for the new year; so, here are my foolish high-level goals in some unknown order:\n\n1. Be a better husband\n2. Talk less, listen more\n3. Cook more intentionally\n4. Speak more intentionally\n5. Help others more effectively\n6. Write at least 2x per month\n7. Exercise ~5x per week\n\nI hope I'm able to accomplish these. With the exclusion of the last two, these goals aren't particularly measurable (I'll probably find a way to measure them) but I hope to make a good effort. I hope to look back here and attempt to hold myself accountable. Maybe I'll provide an update in June, who knows.\n\nMore specific goals that I have that are much more technical in nature are:\n- Connecting Django Rest Framework (DRF) and React while handling data and localization complexities;\n- Deploying a React Native application to both app stores;\n- Putting in some more hours on Airflow / Cloud Composer;\n- Learning how to train my recommendation models on Kubernetes.\n\nThese will be interesting and I'm making progress on DRF and React but I still have quite a bit of work to do.\n\nHopefully this year will be better, I'm optimistic about it."},"nextPost":{"slug":"data-science-and-fintech","frontmatter":{"title":"Data Science and Fintech","description":"How Data Science Scaled the Fintech Revolution","date":"January 22, 2021"},"excerpt":"","content":"\nI've spent the last 10 years working in data science, mostly in Fintech and it's been really exciting to have seen how data science, engineering, and the internet has reshaped all aspects of finance.\n\n[Others have written before](https://fintechtoday.substack.com/p/part-1-what-is-fintech-30-anyway) about how Fintech has evolved from 0.0 to 3.0 over the last decade and one area that I think is interesting is how data science and analytics has helped fuel that growth.\n\n>So, how ***exactly*** has data science helped scale fintech?\n\nI think data science has scales fintech in five key areas.\n\n## 1. Operations\n\nThe market tends to have a preference for technology companies because of the operational efficiencies that come from technology's scale. Simply put, data scientists help identify data and processes that can be automated to help achieve better operational efficiency.\n\nA concrete Fintech example of this is fraud operations. If you're a bank with a credit card product, manually reviewing even 10% of your credit card transactions would be an impossible task (it's been [cited](https://www.marketwatch.com/story/why-bitcoin-wont-displace-visa-or-mastercard-soon-2017-12-15) that Visa and Mastercard process 5,000 transactions per second).\n\nSo, in this circumstance data scientists will build models to reduce the amount of review needed through predictive models.\n\n## 2. Marketing\n\nIn Fintech, Customer Acquisition Cost (CAC) is everything. Others have written about [CAC and Fintech](https://medium.com/unifimoney/the-no-cac-bank-5e0e577d5473) in greater depth, but suffice it to say it is a challenging and competitive problem.\n\nData scientists focused on marketing try to reduce CAC through a wide variety of strategies.\nSome of them are by tightly monitoring product metrics to see which features yield the best ROI on growth, while other approaches take a broader lense by trying to take a comprehensive view of your marketing investments and, again, optimizee the expected return (e.g., through [Marketing Mix Models](https://blog.hurree.co/blog/marketing-mix-modeling)).\n\nOther approaches are more focused on [\"propensity models\"](https://medium.com/the-official-integrate-ai-blog/heres-what-you-need-to-know-about-propensity-modeling-521ab660cb43) and trying to maximize customer engagement or acquisition. Sometimes this involves building propensity models to convert a customer from an email subscriber to a fully-converted user (e.g., for a lending product or a mobile application), while other propensities may focus on simply getting a customer to re-engage with your product.\n\n## 3. Risk Management\n\nThis is where I've spent most of my career and I think it's a really hard problem that most fintechs struggle with in the lending space.\nGenerally speaking, data scientists will build risk models (e.g., for credit risk or fraud risk) to predict the probability of default or some likelihood of delinquency ([more on the difference between them](https://www.investopedia.com/ask/answers/062315/what-are-differences-between-delinquency-and-default.asp)).\n\nBuilding good predictive models is hard. Building good *risk* models is extremely hard.\n\nThis is less because of a technology or data problem and more because of regulatory checks and balances in place. Making sure that you adhere to [FCRA](https://www.ftc.gov/enforcement/statutes/fair-credit-reporting-act) and [ECOA](https://uscode.house.gov/view.xhtml?req=granuleid%3AUSC-prelim-title15-chapter41-subchapter4&edition=prelim) and other regulatory oversight is hard on its own, adding statistical analysis into the mix makes it even harder.\n\nImplementation (i.e., getting an algorithm in production that impacts your customers) of these models is a whole other area of data science and one of the areas I personally find quite fun (maybe I'll write more abou this topic later).\n\n## 4. Technology\n\nData scientists often work with engineering/technology teams in order to improve the technology stack. This may involve changing an architecture to reducy latency of certain services or enhancing the curent stack for a unique problem (cue machine learning and [Airflow DAGs](https://airflow.apache.org)).\nWhile some of this is behind the scenes, it can be some of the most impactful work done by a data scientist in the fintech space because of the broader impact of the items mentioned above.\n\n## 5. Customer Experience\n\nData scientists working with product teams are often tasked with measurement of different experiences within the product and finding out ways to enhance it. That can vary from creating dashboards to monitoring the right metrics to building a recommendation system to curate something specific for a user. Data scientists can fuel product growth, which is why [Facebook, Google, Amazon, Microsoft](https://www.datasciencedegreeprograms.net/lists/five-of-the-largest-companies-that-employ-data-scientists/) and other tech companies hire so many data scientists.\n\nI'll probably write more technical examples of each one of these to give a more concrete information with code and diagrams but I wanted to keep this post high-level to introduce the topics.\n\nSo, to summarize, data scientists are useful (particularly in Fintech) when there are hard problems and data available to solve them.\n\n***\nHave some feedback? Feel free to [let me know](https://twitter.com/franciscojarceo)!"}},"__N_SSG":true}